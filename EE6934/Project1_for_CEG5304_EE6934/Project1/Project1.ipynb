{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project1: Get to know the data\n",
    "Project1 introduces you the Fashion Mnist dataset with some useful preprocessing and visualization methods, and covers Support Vectors Classification (SVC) for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../../homework\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fashion Mnist \n",
    "Read [here](https://github.com/zalandoresearch/fashion-mnist) to learn more about the Fashion Mnist  dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion Mnist  data\n",
    "import mnist_reader\n",
    "trainX, trainy = mnist_reader.load_mnist('../data/', kind='train')\n",
    "testX, testy = mnist_reader.load_mnist('../data/', kind='t10k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some statistics about the data\n",
    "print(\"train image data shape:\", trainX.shape)\n",
    "print(\"train label data shape:\", trainy.shape)\n",
    "print(\"test image data shape:\", testX.shape)\n",
    "print(\"test label data shape:\", testy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualize the flattened data (20 Points)\n",
    "The 28x28 Fashion Mnist images have been flattened as 784 x 1 image vectors.\n",
    "\n",
    "Flattening the data will lead to some loss of information (such as spatial correlation between pixels) but it is nevertheless useful for training some linear classifiers.\n",
    "\n",
    "Write some code below to visualize the training “flattened” data. Please provide a brief analysis about the characteristics of flattened data from visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# TODO:                                                              #\n",
    "# Visualize the data to analyze the characteristics of flattened data#\n",
    "######################################################################\n",
    "# your code\n",
    "######################################################################\n",
    "\n",
    "\n",
    "\n",
    "#                       END OF YOUR CODE                             #\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize the 2D averaged data  (20 Points)\n",
    "Please write some code to reshape the training flattened data back to 2D 28x28 images and plot every \"average\" images of classes 0-9. Please provide a brief analysis about the difference between the 2D images and flattened data of Fashion Mnist from visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# TODO:                                                             #\n",
    "# Plot each \"average image\" of classes 0-9                          #\n",
    "#####################################################################\n",
    "# your code\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#                       END OF YOUR CODE                            #\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement PCA analysis for the flattened data (30 Points)\n",
    "Please write some code to implement the Principle Component Analysis (PCA) analysis for the training flattened data, and plot the <font color=black>**first 100 points of**</font> the first principle component against the second principle component. Note: please plot the components in different colors according to their classes. The coordinate of each point is (first_principle_component, second_principle_component).\n",
    "\n",
    "From the visualization, please give a brief discussion on whether the first principle component and second principle component is sufficient to classify the 10 classes of flattened data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Normalized data to zero mean (5 Points)\n",
    "In this step, please write a method to normalized the flatten data to zero mean one variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(data):\n",
    "    # your code starts here\n",
    "    \n",
    "#####################################################################\n",
    "#                       END OF YOUR CODE                            #\n",
    "#####################################################################\n",
    "    return normalized_data\n",
    "#test\n",
    "output = Normalization(trainX)\n",
    "print(output.mean(),output.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 PCA implementation using numpy (15 Points)\n",
    "In this step, please implement the PCA using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# TODO:                                                             #\n",
    "# Implement PCA analysis for the 2D flattened data  \n",
    "# Hint: You can only use numoy to implement the codes for PCA\n",
    "#     use np.linalg.eig             \n",
    "#####################################################################\n",
    "\n",
    "def PCA(trainX, k): # k is the number of new dimensions \n",
    "    norm_X = Normalization(trainX)\n",
    "    \n",
    "# your code starts here\n",
    "\n",
    "\n",
    "    \n",
    "#####################################################################\n",
    "#                       END OF YOUR CODE                            #\n",
    "#####################################################################\n",
    "    return new_data[:,:k],eigenvalues\n",
    "#test\n",
    "output,eigenvalues = PCA(trainX,2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Ploting of the principle components. (10 Points)\n",
    "In this step, please plot the first and second principle components of the first 100 samples using matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# TODO:                                                             #\n",
    "# PCA analysis for the 2D flattened data  \n",
    "# Hint: from sklearn.decomposition import PCA\n",
    "#       use PCA(svd_solver='auto').fit_transform(trainX) \n",
    "#       to compute the PCA of trainX                                #\n",
    "#####################################################################\n",
    "# your code starts here\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#                       END OF YOUR CODE                            #\n",
    "#####################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use Support Vectors Classification (SVC) to classify the principle components (PC) of training flattened data (30 Points)\n",
    "\n",
    "Please write some code to train the Support Vectors Classification (SVC) using the <font color=black>**ALL Training Data**</font>. Then, evaluate the trained SCV on the test dataset. \n",
    "\n",
    "For each of the 100 nodes, its coordinate is (firstPC, secondPC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Concatenate train and test data (5 Points)\n",
    "In this step, please concatenate the train and test data for PCA, and get the principle components (PC with k = 2) of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Concatenate(trainX,testX,k=2):\n",
    "# your code starts here\n",
    "\n",
    "    \n",
    "#####################################################################\n",
    "#                       END OF YOUR CODE                            #\n",
    "#####################################################################\n",
    "    return norm_trainX,norm_testX,eigenvalues\n",
    "#test \n",
    "norm_trainX,norm_testX,eigenvalues = Concatenate(trainX,testX,2)\n",
    "print(norm_trainX.shape,norm_testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Support Vectors Classification (SVC) (10 Points)\n",
    "\n",
    "In this step, please write the code to train a SVC for classification. You may use the skelarn SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "norm_trainX,norm_testX,eigenvalues = Concatenate(trainX,testX,2)\n",
    "def train_SVC(X, Y,testX,testY):\n",
    "#####################################################################\n",
    "# TODO:                                                             #\n",
    "# Hint: from sklearn import svm \n",
    "#       please return the accuracy over the test set                #\n",
    "#####################################################################\n",
    "    svc = svm.SVC()\n",
    "\n",
    "# your code starts here\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "#                       END OF YOUR CODE                            #\n",
    "#####################################################################\n",
    "    #return accuracy\n",
    "    return 0 \n",
    "#test\n",
    "print(\"test accuracy is {}\".format(train_SVC(norm_trainX[:1000],trainy[:1000],norm_testX[:1000],testy[:1000])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Scree Plot of PCA component  (10 Points)\n",
    "\n",
    "In this step, plot the [scree plot](https://en.wikipedia.org/wiki/Scree_plot#:~:text=The%20scree%20plot%20is%20used,known%20as%20a%20scree%20test.) displays of PCA to select the proper k for training SVC. Y axis is the cumulated variance, and x axis is the number of priciple components (PC). Please only plot the first 10 PC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scree(trainX,trainy,testX,testy,k=2):\n",
    "    no_components_to_cal = 10\n",
    "    norm_trainX,norm_testX,eigenvalues = Concatenate(trainX,testX,k)\n",
    "    \n",
    "    ### Your code starts here ###############################################################\n",
    "    \n",
    "\n",
    "    ### Your code ends here #################################################################\n",
    "#test \n",
    "plot_scree(trainX,trainy,testX,testy,k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Retrain SVC based on the optimal k obtained from the scree plot (5 Points)\n",
    "\n",
    "In this step, please choose the optimal k based on the scree plot to retrain the svc. k should be less of equal than 10. Please do it based on the methods you realized previously. Only Train and test first 1000 samples as we do in 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_SVC(trainX,trainy,testX,testy):\n",
    "    no_to_train = 1000\n",
    "    no_to_test = 1000\n",
    "    ### Your code starts here ###############################################################\n",
    "\n",
    "    ### Your code ends here #################################################################\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "#test\n",
    "accuracy = retrain_SVC(trainX,trainy,testX,testy)\n",
    "print(\"accuracy is {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your submission, in addition to the completed codes and the resulting images for the visualizations, also provide brief responses to the above questions and a brief analysis of the visualized data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 21:12:53) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e98360397c957520f6191d2085167ffb6b4260bd84c5d4d61561dd2fe86f988b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
